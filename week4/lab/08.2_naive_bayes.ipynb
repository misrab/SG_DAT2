{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classification\n",
    "\n",
    "Concepts in this Notebook:\n",
    "- Naive Bayes Classifiers\n",
    "- Train Test Split\n",
    "- Vectorizer (fit and transform)\n",
    "- Accuracy of training and test data\n",
    "- Sparse array vs normal array\n",
    "- Comparing classifiers in sklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some extra resources:\n",
    "\n",
    "- [SKL Naive Bayes Documentation](http://scikit-learn.org/stable/modules/naive_bayes.html)\n",
    "\n",
    "- [Stanford Naive Bayes Math](http://nlp.stanford.edu/IR-book/pdf/13bayes.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "critics = pd.read_csv('https://raw.githubusercontent.com/gfleetwood/fall-2014-lessons/master/datasets/rt_critics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A winning animated feature that has something for everyone on the age spectrum.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critics.quote[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>        Derek Adams</td>\n",
       "      <td> fresh</td>\n",
       "      <td> 114709</td>\n",
       "      <td>       Time Out</td>\n",
       "      <td> So ingenious in concept, design and execution ...</td>\n",
       "      <td> 2009-10-04</td>\n",
       "      <td> 9559</td>\n",
       "      <td> Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>    Richard Corliss</td>\n",
       "      <td> fresh</td>\n",
       "      <td> 114709</td>\n",
       "      <td>  TIME Magazine</td>\n",
       "      <td>                 The year's most inventive comedy.</td>\n",
       "      <td> 2008-08-31</td>\n",
       "      <td> 9559</td>\n",
       "      <td> Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>        David Ansen</td>\n",
       "      <td> fresh</td>\n",
       "      <td> 114709</td>\n",
       "      <td>       Newsweek</td>\n",
       "      <td> A winning animated feature that has something ...</td>\n",
       "      <td> 2008-08-18</td>\n",
       "      <td> 9559</td>\n",
       "      <td> Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>      Leonard Klady</td>\n",
       "      <td> fresh</td>\n",
       "      <td> 114709</td>\n",
       "      <td>        Variety</td>\n",
       "      <td> The film sports a provocative and appealing st...</td>\n",
       "      <td> 2008-06-09</td>\n",
       "      <td> 9559</td>\n",
       "      <td> Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> Jonathan Rosenbaum</td>\n",
       "      <td> fresh</td>\n",
       "      <td> 114709</td>\n",
       "      <td> Chicago Reader</td>\n",
       "      <td> An entertaining computer-generated, hyperreali...</td>\n",
       "      <td> 2008-03-10</td>\n",
       "      <td> 9559</td>\n",
       "      <td> Toy story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               critic  fresh    imdb     publication                                              quote review_date  rtid      title\n",
       "0         Derek Adams  fresh  114709        Time Out  So ingenious in concept, design and execution ...  2009-10-04  9559  Toy story\n",
       "1     Richard Corliss  fresh  114709   TIME Magazine                  The year's most inventive comedy.  2008-08-31  9559  Toy story\n",
       "2         David Ansen  fresh  114709        Newsweek  A winning animated feature that has something ...  2008-08-18  9559  Toy story\n",
       "3       Leonard Klady  fresh  114709         Variety  The film sports a provocative and appealing st...  2008-06-09  9559  Toy story\n",
       "4  Jonathan Rosenbaum  fresh  114709  Chicago Reader  An entertaining computer-generated, hyperreali...  2008-03-10  9559  Toy story"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial vs Bernoulli Models\n",
    "\n",
    "- The **Multinomial model** actually counts occurences out of all possible occurences for probability - better for greater features\n",
    "- The **Bernoulli model** counts only all documents with presence of the word - better for fewer features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO - import both versions of naive bayes from sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How the Count Vectorizer Works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "\tMath is great\n",
      "\tMath is really great\n",
      "\tExciting exciting Math\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "### How the Count Vectorizer Works\n",
    "#\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "text = ['Math is great', 'Math is really great', 'Exciting exciting Math']\n",
    "print \"Original text:\\n\\t\", '\\n\\t'.join(text)\n",
    "\n",
    "# TODO - create the instance of CountVectorizer class. Specify the ngram_range argument (see docs)\n",
    "\n",
    "# TODO - call `fit` on the text to build the vocabulary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: What is an ngram?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'exciting',\n",
       " u'exciting exciting',\n",
       " u'exciting math',\n",
       " u'great',\n",
       " u'is',\n",
       " u'is great',\n",
       " u'is really',\n",
       " u'math',\n",
       " u'math is',\n",
       " u'really',\n",
       " u'really great']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the names of the features (n grams)\n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO call `transform` to convert text to a bag of words\n",
    "# x = ...\n",
    "print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1],\n",
       "       [2, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CountVectorizer uses a sparse array to save memory, but it's easier in this assignment to \n",
    "# convert back to a \"normal\" numpy array\n",
    "x_back = x.toarray()\n",
    "x_back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed text vector is \n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 8)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 9)\t1\n",
      "  (1, 10)\t1\n",
      "  (2, 0)\t2\n",
      "  (2, 1)\t1\n",
      "  (2, 2)\t1\n",
      "  (2, 7)\t1\n",
      "\n",
      "Words for each feature:\n",
      "[u'exciting', u'exciting exciting', u'exciting math', u'great', u'is', u'is great', u'is really', u'math', u'math is', u'really', u'really great']\n"
     ]
    }
   ],
   "source": [
    "print \"Transformed text vector is \\n\", x\n",
    "\n",
    "# `get_feature_names` tracks which word is associated with each column of the transformed x\n",
    "print\n",
    "print \"Words for each feature:\"\n",
    "print vectorizer.get_feature_names()\n",
    "\n",
    "# Notice that the bag of words treatment doesn't preserve information about the *order* of words, \n",
    "# just their frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing our Features (X) and Target (Y) for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X is a (nreview, nwords) array. Each row corresponds to a bag-of-words representation for a single review. This will be the input to the model.\n",
    "\n",
    "Y is a nreview-element 1/0 array, encoding whether a review is Fresh (1) or Rotten (0). This is the desired output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Instantiate the vectorizer with n-grams of length one or two\n",
    "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "\n",
    "# Create a vector where each row is bag-of-words for a single quote\n",
    "X = vectorizer.fit_transform(critics.quote) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO - Create an array where each element encodes whether the array is Fresh or Rotten\n",
    "# Y = ...\n",
    "# hint: apply the == condition, then use .values.astype(np.int) on the result to get the right type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use SKLearn's train_test_split\n",
    "# Important - we'll do this a thousand times\n",
    "from sklearn.cross_validation import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vector of all quotes\n",
    "rotten_vectorizer = vectorizer.fit(critics.quote)\n",
    "\n",
    "# a few helper functions\n",
    "def accuracy_report(_clf):\n",
    "    print \"Accuracy: %0.2f%%\" % (100 * _clf.score(xtest, ytest))\n",
    "\n",
    "    #Print the accuracy on the test and training dataset\n",
    "    training_accuracy = _clf.score(xtrain, ytrain)\n",
    "    test_accuracy = _clf.score(xtest, ytest)\n",
    "\n",
    "    print \"Accuracy on training data: %0.2f\" % (training_accuracy)\n",
    "    \n",
    "# a function to run some tests\n",
    "def AnalyzeReview(testquote, _clf):\n",
    "    print \"\\\"\"  + testquote + \"\\\" is judged by clasifier to be...\"\n",
    "    testquote = rotten_vectorizer.transform([testquote])\n",
    "\n",
    "    if (_clf.predict(testquote)[0] == 1):\n",
    "        print \"... a fresh review.\"\n",
    "    else:\n",
    "        print \"... a rotten review.\"\n",
    "    return(clf.predict(testquote)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB:\n",
      "Accuracy: 76.24%\n",
      "Accuracy on training data: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "print \"MultinomialNB:\"\n",
    "clf_mn = MultinomialNB().fit(xtrain, ytrain)\n",
    "accuracy_report(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "print \"BernoulliNB:\"\n",
    "# TODO - same as above with Bernoulli\n",
    "# clf_b = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "print \"Logistic Regression:\"\n",
    "# TODO - same as above with LogReg\n",
    "# clf_lr = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"This movie was awesome\" is judged by clasifier to be...\n",
      "... a fresh review.\n",
      "\"This movie was awesome\" is judged by clasifier to be...\n",
      "... a fresh review.\n",
      "\"This movie was awesome\" is judged by clasifier to be...\n",
      "... a rotten review.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AnalyzeReview(\"This movie was awesome\", clf_mn)\n",
    "AnalyzeReview(\"This movie was awesome\", clf_b)\n",
    "AnalyzeReview(\"This movie was awesome\", clf_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save prediction and probability\n",
    "\n",
    "# Outputs of X (just first column)\n",
    "prob = clf.predict_proba(X)[:, 0]\n",
    "\n",
    "predict = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y==0 #(provides a mask where the actual review is bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4925,  249, 2369,  174, 2130])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# argsort returns the positions of the top n sorted values\n",
    "np.argsort((prob[Y==0]))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Top 5 Review classification errors\n",
    "bad_rotten = np.argsort(prob[Y == 0])[:5]\n",
    "bad_fresh = np.argsort(prob[Y == 1])[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mis-predicted Rotten quotes\n",
      "---------------------------\n",
      "If you loved Wolfe's book, you may very well hate the movie. If you simply liked the novel, you may be simultaneously entertained and disappointed by what De Palma and Cristofer have done to it.\n",
      "\n",
      "There is absolutely nothing going on in Beautiful Girls that you haven't seen... [in] any other artistic endeavor in which untethered young men and women, bound by geography and fortified by beer, shamble their way toward overdue maturity.\n",
      "\n",
      "Nava, who started his feature-film career with El Norte, is a good director who invariably finds a strong rapport with his actors. He's not much of a writer, though, and he should think twice about creating dialogue for his future projects.\n",
      "\n",
      "Mr. Rodriguez demonstrates his talents more clearly than ever -- he's visually inventive, quick-witted and a fabulous editor -- while still hampering himself with sophomoric material.\n",
      "\n",
      "By its midpoint, however, Thornton has begun forcing both the film's poetry and the preternatural goodness of its simple-minded protagonist, and Sling Blade's sweet charms begin to curdle.\n",
      "\n",
      "Mis-predicted Fresh quotes\n",
      "--------------------------\n",
      "On a mindless exploitation level this is pretty good, but on other levels it seems to make promises that it fails to deliver on.\n",
      "\n",
      "This film is sometimes too familiar, especially in early scenes that deliberately repeat the first film's gags. But the formula isn't tired yet.\n",
      "\n",
      "Though the script is predictable, it's not too clumsy.\n",
      "\n",
      "Supernova, though predictable, isn't half bad.\n",
      "\n",
      "Here is Monty Python and the Holy Grail, which is neither as sparkling as it is said to be nor as bad as it seems to be at the start. But it's pretty good.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"Mis-predicted Rotten quotes\"\n",
    "print '---------------------------'\n",
    "for row in bad_rotten:\n",
    "    print critics[Y == 0].quote.irow(row)\n",
    "    print\n",
    "\n",
    "print \"Mis-predicted Fresh quotes\"\n",
    "print '--------------------------'\n",
    "for row in bad_fresh:\n",
    "    print critics[Y == 1].quote.irow(row)\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
